{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various types of feature detectors like SIFT,FAST and ORB. Here we will see how to use these detected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required things\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the image\n",
    "query_image = cv2.imread('book.jpeg')\n",
    "to_match_image = cv2.imread(\"book_1.jpeg\")\n",
    "\n",
    "\n",
    "#resizing the image for better viewing\n",
    "query_image = cv2.resize(query_image,(500,700))\n",
    "to_match_image = cv2.resize(to_match_image,(500,700))\n",
    "\n",
    "#displaying the image\n",
    "cv2.imshow(\"query\",query_image)\n",
    "cv2.imshow(\"to_match_image\",to_match_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the image in gray scale\n",
    "query_image = cv2.imread('book.jpeg',0)\n",
    "to_match_image = cv2.imread(\"book_1.jpeg\",0)\n",
    "\n",
    "\n",
    "#resizing the image for better viewing\n",
    "query_image = cv2.resize(query_image,(500,700))\n",
    "to_match_image = cv2.resize(to_match_image,(500,700))\n",
    "\n",
    "\n",
    "#Creating the ORB object with 1500 features\n",
    "orb = cv2.ORB_create(nfeatures=1500)\n",
    "\n",
    "#detecting the keypoints\n",
    "kp1, des1 = orb.detectAndCompute(query_image,None)\n",
    "kp2, des2 = orb.detectAndCompute(to_match_image,None)\n",
    "\n",
    "#drawing the keypoints\n",
    "query_image_with_kp = cv2.drawKeypoints(query_image,kp1,None)\n",
    "to_match_image_with_kp = cv2.drawKeypoints(to_match_image,kp2,None)\n",
    "\n",
    "#displaying the image\n",
    "cv2.imshow(\"query\",query_image_with_kp)\n",
    "cv2.imshow(\"to_match_image\",to_match_image_with_kp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got the Keypoints points in the image, Now we have to match the keypoints between both the images, for that we are going to use BruteForce matcher technique.\n",
    "we use the descriptors for matching the keypoints, consider descriptors are the array of values of the detected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 32)\n",
      "(1500, 32)\n"
     ]
    }
   ],
   "source": [
    "#creating the object of the BFmatcher\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "#getting the shape of the descriptors\n",
    "print(des1.shape)\n",
    "print(des1.shape)\n",
    "\n",
    "\n",
    "#applying the BF KNN match\n",
    "matches = bf.knnMatch(des1,des2,k=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got the matches but some matches will not be good, so we are giving some sort of threshold to get only the good matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "#getting the good matches\n",
    "good_matches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good_matches.append([m])\n",
    "print(len(good_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.drawMatchesKnn(query_image,kp1,to_match_image,kp2,good_matches,None,flags=2)\n",
    " \n",
    "\n",
    "    \n",
    "cv2.imshow(\"output\",output)   \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, we got 19 good matches. Now we will play some other image and check the good matches value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 32)\n",
      "(1500, 32)\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#reading the image in gray scale\n",
    "query_image = cv2.imread('book.jpeg',0)\n",
    "to_match_image = cv2.imread(\"redmi_1.jpeg\",0)\n",
    "\n",
    "\n",
    "#resizing the image for better viewing\n",
    "query_image = cv2.resize(query_image,(500,700))\n",
    "to_match_image = cv2.resize(to_match_image,(500,700))\n",
    "\n",
    "\n",
    "#Creating the ORB object with 1500 features\n",
    "orb = cv2.ORB_create(nfeatures=1500)\n",
    "\n",
    "#detecting the keypoints\n",
    "kp1, des1 = orb.detectAndCompute(query_image,None)\n",
    "kp2, des2 = orb.detectAndCompute(to_match_image,None)\n",
    "\n",
    "#drawing the keypoints\n",
    "query_image_with_kp = cv2.drawKeypoints(query_image,kp1,None)\n",
    "to_match_image_with_kp = cv2.drawKeypoints(to_match_image,kp2,None)\n",
    "\n",
    "\n",
    "#creating the object of the BFmatcher\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "#getting the shape of the descriptors\n",
    "print(des1.shape)\n",
    "print(des1.shape)\n",
    "\n",
    "\n",
    "#applying the BF KNN match\n",
    "matches = bf.knnMatch(des1,des2,k=2)\n",
    "\n",
    "\n",
    "#getting the good matches\n",
    "good_matches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good_matches.append([m])\n",
    "print(len(good_matches))\n",
    "\n",
    "#displaying the image\n",
    "\n",
    "\n",
    "output = cv2.drawMatchesKnn(query_image,kp1,to_match_image,kp2,good_matches,None,flags=2)\n",
    " \n",
    "\n",
    "    \n",
    "cv2.imshow(\"output\",output)   \n",
    "cv2.imshow(\"query\",query_image_with_kp)\n",
    "cv2.imshow(\"to_match_image\",to_match_image_with_kp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Time we got only 9 good matches, so the simple logic is the more the good matches you have the more the object is classified rately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
